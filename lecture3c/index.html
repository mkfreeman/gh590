<!doctype html>
<html lang="en">
<head>
	<meta charset="utf-8">

	<title>Lecture 3c</title>

	<link rel="stylesheet" href="../reveal/css/reveal.min.css">
	<link rel="stylesheet" href="../reveal/css/theme/default.css" id="theme">

	<!-- For syntax highlighting -->
	<link rel="stylesheet" href="../reveal/lib/css/zenburn.css">

	<!-- If the query includes 'print-pdf', include the PDF print sheet -->
	<script>
		if( window.location.search.match( /print-pdf/gi ) ) {
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = 'css/print/pdf.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		}
	</script>
	<script src="http://d3js.org/d3.v3.min.js"></script>



</head>

<body>

	<div class="reveal">

		<div class="slides">
			<section>
			<h2>Graphical Perception (1/2)</h2>
			</section>
			
			<section>
			<h3>Outline</h3>
				<ul>
					<li class="fragment">Role of graphical perception</li>
					<li class="fragment">Sensory versus arbitrary representation</li>
					<li class="fragment">Model of perceptual processing</li>
					<li class="fragment">Types of data</li>
					<li class="fragment">Preattentive processing</li>					
				</ul>
			</section>
			<section>
				<section>
					<h3>Role of graphical perception</h3>
				</section>
				<section>
					<h3>Visualization process</h3>
					<img class="stretch fragment" id="viz_process1" src="../reveal/lib/imgs/viz_process1.png"></img>
					<div class="fragment" id='viz_process2' style="height:0px; width:0px;"></div>
					<div class="fragment" id='viz_process3' style="height:0px; width:0px;"></div>
					<div class="fragment" id='viz_process4' style="height:0px; width:0px;"></div>
					<div class="fragment" id='viz_process5' style="height:0px; width:0px;"></div>
					<div class="fragment" id='viz_process6' style="height:0px; width:0px;"></div>
				</section>
				<section>
					<h3>Graphical perception</h3>
					<blockquote class="fragment">
						&ldquo;The visual decoding of information encoded in graphs&rdquo; - Cleveland/McGill
					</blockquote>
					<ul>
						<li class="fragment" style="text-align:left;">Our task: encode data with graphical properties that are most easily/accurately decoded</li>
						<li class="fragment" style="text-align:left;">Semiotics of graphics</li>
					</ul>
					<blockquote class="fragment">
						&ldquo;The study of symbols and how they convey meaning&rdquo; - Ware 2004
					</blockquote>
				</section>
				<section>
					<h3>Is this possible?</h3>
					<ul>
						<li class="fragment">Can there be a science of visualization?</li>
						<li class="fragment">Arbitrariness (Saussure)</li>
						<li class="fragment">Cultural relativism</li>
						<li class="fragment"><a target="_blank" href="http://ifs.tuwien.ac.at/~silvia/wien/vu-infovis/articles/book_information-visualization-perception-for-design_Ware_Chapter1.pdf">Ware 2004</a></li>
					</ul>
				</section>
			</section>
			<section>
				<section>
					<h3>Sensory versus arbitrary symbols</h3>
				</section>
				<section>
					<h3>Definitions</h3>
					<ul>
						<li class="fragment"><b>Sensory:</b> meaning derived without learning</li>
						<li class="fragment"><b>Arbitrary:</b> understanding depends on learned information</li>
					</ul>
				</section>
				<section>
					<h3>Sensory symbols</h3>
					<ul>
						<li class="fragment">Understanding without training</li>
						<li class="fragment">Resistance to instructional bias</li>
						<li class="fragment">Sensory immediacy</li>
						<li class="fragment">Cross-cultural validity</li>
					</ul>
				</section>	
				<section>
					<h3>Understanding without training</h3>
					<img class="fragment" src="../reveal/lib/imgs/sensory.png"></img>
				</section>
				<section>
					<h3>Resistance to instructional bias</h3>
					<img class="fragment" src="../reveal/lib/imgs/muller1.png"></img>
					<img class="fragment" src="../reveal/lib/imgs/muller2.png"></img>
				</section>
				<section>
					<h3>Arbitrary symbols</h3>
					<ul>
						<li class="fragment">Hard to learn</li>
						<li class="fragment">Easy to forget</li>
						<li class="fragment">Embedded in culture and applications</li>
						<li class="fragment">Formally powerful</li>
						<li class="fragment">Capable of change</li>
					</ul>
				</section>
				<section>
					<img src="../reveal/lib/imgs/street_signs.png"></img>
				</section>
				<section>
					<img src="../reveal/lib/imgs/carrot.png"></img>
				</section>
				<section>
					<img src="../reveal/lib/imgs/math.png"></img>
				</section>
				<section>
					<h3>Sensory versus arbitrary</h3>
					<img class="fragment" src="../reveal/lib/imgs/sensory_v_arbitrary.png"></img>
				</section>
			</section>
			<section>
				<section>
					<h3>Model of perceptual processing</h3>
				</section>
				<section>
					<h3>Three stages</h3>
					<ul>
						<li class="fragment">Stage 1: Parallel processing of low level information</li>
						<li class="fragment">Stage 2: Pattern perception</li>
						<li class="fragment">Stage 3: Goal directed processing</li>
					</ul>
				</section>
				<section>
					<h3>Stage 1</h3>
					<ul>
						<li class="fragment">Neurons process information in parallel</li>
						<li class="fragment">Extract features (color, texture, movement, orientation)</li>
					</ul>
					<img class="fragment" src="../reveal/lib/imgs/stage1.png"></img>
				</section>
				<section>
					<h3>Stage 2</h3>
					<ul>
						<li class="fragment">Slower serial processing</li>
						<li class="fragment">More detailed processes such as segmentation</li>
					</ul>
					<img class="fragment" src="../reveal/lib/imgs/stage2.png"></img>
				</section>
				<section>
					<h3>Stage 3</h3>
					<ul>
						<li class="fragment">Executing advanced visual queries</li>
						<li class="fragment">Requires active attention</li>
					</ul>
					<img class="fragment" src="../reveal/lib/imgs/stage3.png"></img>
				</section>
			</section>
			<section>
				<section>
					<h3>Types of data</h3>
				</section>
				<section>
					<h3>Data structure</h3>
					<ul>
						<li class="fragment">Entities: objects of interest</li>
						<li class="fragment">Relationships: structures between entities</li>
						<li class="fragment">Entities and relationships both can be described with data attributes</li>
						<li class="fragment"><a href="http://vizhub.healthdata.org/us-health-map" target="_blank">Example</a></li>
					</ul>
				</section>
				<section>
					<h3>Data attributes</h3>
					<ul>
						<li class="fragment">Nominal: no inherent ordering of values</li>
						<pre class="fragment">Fruits: apples, bananas, oranges</pre>
						<li class="fragment">Ordinal: ordered values with unknown distances between them</li>
						<pre class="fragment">Quality: low, medium, high</pre>
						<li class="fragment">Quantitative (interval): Only interval is meaningful</li>
						<pre class="fragment">Date: 2/15/77, 3/18/66</pre>
						<li class="fragment">Quantitative (ratio): zero is fixed</li>
						<pre class="fragment">Physical measurements, counts, etc.</pre>
					</ul>
				</section>
			</section>
			<section>
				<section>
					<h3>Preattentive cognition</h3>
				</section>
				<section>
					<h3>Features</h3>
					<ul>
						<li class="fragment">Processing prior to conscious attention</li>
						<li class="fragment">Resistant to distractors</li>
						<li class="fragment">Rooted in sensory symbols</li>
					</ul>		

				</section>
				<section>
					<img src="../reveal/lib/imgs/ware2.png"></img>
				</section>
				<section>
					<img src="../reveal/lib/imgs/ware1.png"></img>
				</section>
			
				<section>
					<h3>Are all preattetive attribues equally effective?</h3>
					<img class="fragment" src="../reveal/lib/imgs/distractors.png"></img>
				</section>
				<section>
					<h3>Semantic depth of field</h3>
					<img class="fragment" src="../reveal/lib/imgs/blur.png"></img>
				</section>
				<section>
					<h3>Using color</h3>
					<p><a href="http://ihmeuw.org/25l8">Link</a></p>
				</section>
			</section>
		</div>
	</div>
	<script src="../reveal/lib/js/head.min.js"></script>
	<script src="../reveal/js/reveal.min.js"></script>


	<script>
		Reveal.initialize({
			controls: true,
			progress: true,
			history: true,
			center: true,

			theme: Reveal.getQueryHash().theme, 
			transition: Reveal.getQueryHash().transition || 'default',
			dependencies: [
				{ src: '../reveal/lib/js/classList.js', condition: function() { return !document.body.classList; } },
				{ src: '../reveal/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: '../reveal/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
				{ src: '../reveal/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
				{ src: '../reveal/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
				{ src: '../reveal/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
			]
		});
		Reveal.addEventListener('fragmentshown', function(event) {		
			if(event.fragment.id.indexOf('viz')!=-1) d3.select('#viz_process1').attr('src', '../reveal/lib/imgs/' + event.fragment.id + '.png')
		
		})
		Reveal.addEventListener('fragmenthidden', function(event) {
			if(event.fragment.id.indexOf('viz')!=-1) { 
				var value = 'viz_process' + (Number(event.fragment.id.replace('viz_process', '')) - 1)
				d3.select('#viz_process1').attr('src', '../reveal/lib/imgs/' + value + '.png')
			}
		
		})
	</script>

</body>
</html>
